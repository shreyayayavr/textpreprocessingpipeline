{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54601774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32db345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"D:/Downloads/sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b31d3112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  \\\n",
      "0   @AppleSupport causing the reply to be disregar...   \n",
      "1   @105835 Your business means a lot to us. Pleas...   \n",
      "2   @76328 I really hope you all change but I'm su...   \n",
      "3   @105836 LiveChat is online at the moment - htt...   \n",
      "4   @VirginTrains see attached error message. I've...   \n",
      "..                                                ...   \n",
      "88  @105860 I wish Amazon had an option of where I...   \n",
      "89  They reschedule my shit for tomorrow https://t...   \n",
      "90  @105861 Hey Sara, sorry to hear of the issues ...   \n",
      "91  @Tesco bit of both - finding the layout cumber...   \n",
      "92  @105861 If that doesn't help please DM your fu...   \n",
      "\n",
      "                                   sentence_tokenized  \n",
      "0   [@AppleSupport causing the reply to be disrega...  \n",
      "1   [@105835 Your business means a lot to us., Ple...  \n",
      "2   [@76328 I really hope you all change but I'm s...  \n",
      "3   [@105836 LiveChat is online at the moment - ht...  \n",
      "4   [@VirginTrains see attached error message., I'...  \n",
      "..                                                ...  \n",
      "88  [@105860 I wish Amazon had an option of where ...  \n",
      "89  [They reschedule my shit for tomorrow https://...  \n",
      "90  [@105861 Hey Sara, sorry to hear of the issues...  \n",
      "91  [@Tesco bit of both - finding the layout cumbe...  \n",
      "92  [@105861 If that doesn't help please DM your f...  \n",
      "\n",
      "[93 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data['sentence_tokenized'] = data['text'].apply(sent_tokenize)\n",
    "\n",
    "print(data[['text', 'sentence_tokenized']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c413a8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  \\\n",
      "0   @AppleSupport causing the reply to be disregar...   \n",
      "1   @105835 Your business means a lot to us. Pleas...   \n",
      "2   @76328 I really hope you all change but I'm su...   \n",
      "3   @105836 LiveChat is online at the moment - htt...   \n",
      "4   @VirginTrains see attached error message. I've...   \n",
      "..                                                ...   \n",
      "88  @105860 I wish Amazon had an option of where I...   \n",
      "89  They reschedule my shit for tomorrow https://t...   \n",
      "90  @105861 Hey Sara, sorry to hear of the issues ...   \n",
      "91  @Tesco bit of both - finding the layout cumber...   \n",
      "92  @105861 If that doesn't help please DM your fu...   \n",
      "\n",
      "                                       tokenized_text  \n",
      "0   [@, AppleSupport, causing, the, reply, to, be,...  \n",
      "1   [@, 105835, Your, business, means, a, lot, to,...  \n",
      "2   [@, 76328, I, really, hope, you, all, change, ...  \n",
      "3   [@, 105836, LiveChat, is, online, at, the, mom...  \n",
      "4   [@, VirginTrains, see, attached, error, messag...  \n",
      "..                                                ...  \n",
      "88  [@, 105860, I, wish, Amazon, had, an, option, ...  \n",
      "89  [They, reschedule, my, shit, for, tomorrow, ht...  \n",
      "90  [@, 105861, Hey, Sara, ,, sorry, to, hear, of,...  \n",
      "91  [@, Tesco, bit, of, both, -, finding, the, lay...  \n",
      "92  [@, 105861, If, that, does, n't, help, please,...  \n",
      "\n",
      "[93 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data['tokenized_text'] = data['text'].apply(word_tokenize)\n",
    "print(data[['text', 'tokenized_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22cf45c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  \\\n",
      "0   @AppleSupport causing the reply to be disregar...   \n",
      "1   @105835 Your business means a lot to us. Pleas...   \n",
      "2   @76328 I really hope you all change but I'm su...   \n",
      "3   @105836 LiveChat is online at the moment - htt...   \n",
      "4   @VirginTrains see attached error message. I've...   \n",
      "..                                                ...   \n",
      "88  @105860 I wish Amazon had an option of where I...   \n",
      "89  They reschedule my shit for tomorrow https://t...   \n",
      "90  @105861 Hey Sara, sorry to hear of the issues ...   \n",
      "91  @Tesco bit of both - finding the layout cumber...   \n",
      "92  @105861 If that doesn't help please DM your fu...   \n",
      "\n",
      "                                    subword_tokenized  \n",
      "0   [@, apples, ##up, ##port, causing, the, reply,...  \n",
      "1   [@, 105, ##8, ##35, your, business, means, a, ...  \n",
      "2   [@, 76, ##32, ##8, i, really, hope, you, all, ...  \n",
      "3   [@, 105, ##8, ##36, live, ##cha, ##t, is, onli...  \n",
      "4   [@, virgin, ##train, ##s, see, attached, error...  \n",
      "..                                                ...  \n",
      "88  [@, 105, ##86, ##0, i, wish, amazon, had, an, ...  \n",
      "89  [they, res, ##ched, ##ule, my, shit, for, tomo...  \n",
      "90  [@, 105, ##86, ##1, hey, sara, ,, sorry, to, h...  \n",
      "91  [@, te, ##sco, bit, of, both, -, finding, the,...  \n",
      "92  [@, 105, ##86, ##1, if, that, doesn, ', t, hel...  \n",
      "\n",
      "[93 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "data['subword_tokenized'] = data['text'].apply(lambda x: tokenizer.tokenize(x))\n",
    "print(data[['text', 'subword_tokenized']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f4e527f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  \\\n",
      "0   @AppleSupport causing the reply to be disregar...   \n",
      "1   @105835 Your business means a lot to us. Pleas...   \n",
      "2   @76328 I really hope you all change but I'm su...   \n",
      "3   @105836 LiveChat is online at the moment - htt...   \n",
      "4   @VirginTrains see attached error message. I've...   \n",
      "..                                                ...   \n",
      "88  @105860 I wish Amazon had an option of where I...   \n",
      "89  They reschedule my shit for tomorrow https://t...   \n",
      "90  @105861 Hey Sara, sorry to hear of the issues ...   \n",
      "91  @Tesco bit of both - finding the layout cumber...   \n",
      "92  @105861 If that doesn't help please DM your fu...   \n",
      "\n",
      "                                       char_tokenized  \n",
      "0   [@, A, p, p, l, e, S, u, p, p, o, r, t,  , c, ...  \n",
      "1   [@, 1, 0, 5, 8, 3, 5,  , Y, o, u, r,  , b, u, ...  \n",
      "2   [@, 7, 6, 3, 2, 8,  , I,  , r, e, a, l, l, y, ...  \n",
      "3   [@, 1, 0, 5, 8, 3, 6,  , L, i, v, e, C, h, a, ...  \n",
      "4   [@, V, i, r, g, i, n, T, r, a, i, n, s,  , s, ...  \n",
      "..                                                ...  \n",
      "88  [@, 1, 0, 5, 8, 6, 0,  , I,  , w, i, s, h,  , ...  \n",
      "89  [T, h, e, y,  , r, e, s, c, h, e, d, u, l, e, ...  \n",
      "90  [@, 1, 0, 5, 8, 6, 1,  , H, e, y,  , S, a, r, ...  \n",
      "91  [@, T, e, s, c, o,  , b, i, t,  , o, f,  , b, ...  \n",
      "92  [@, 1, 0, 5, 8, 6, 1,  , I, f,  , t, h, a, t, ...  \n",
      "\n",
      "[93 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data['char_tokenized'] = data['text'].apply(lambda x: list(x))\n",
    "\n",
    "# Display the character tokenized text\n",
    "print(data[['text', 'char_tokenized']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31c7be11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  \\\n",
      "0   @AppleSupport causing the reply to be disregar...   \n",
      "1   @105835 Your business means a lot to us. Pleas...   \n",
      "2   @76328 I really hope you all change but I'm su...   \n",
      "3   @105836 LiveChat is online at the moment - htt...   \n",
      "4   @VirginTrains see attached error message. I've...   \n",
      "..                                                ...   \n",
      "88  @105860 I wish Amazon had an option of where I...   \n",
      "89  They reschedule my shit for tomorrow https://t...   \n",
      "90  @105861 Hey Sara, sorry to hear of the issues ...   \n",
      "91  @Tesco bit of both - finding the layout cumber...   \n",
      "92  @105861 If that doesn't help please DM your fu...   \n",
      "\n",
      "                                           text_lower  \\\n",
      "0   @applesupport causing the reply to be disregar...   \n",
      "1   @105835 your business means a lot to us. pleas...   \n",
      "2   @76328 i really hope you all change but i'm su...   \n",
      "3   @105836 livechat is online at the moment - htt...   \n",
      "4   @virgintrains see attached error message. i've...   \n",
      "..                                                ...   \n",
      "88  @105860 i wish amazon had an option of where i...   \n",
      "89  they reschedule my shit for tomorrow https://t...   \n",
      "90  @105861 hey sara, sorry to hear of the issues ...   \n",
      "91  @tesco bit of both - finding the layout cumber...   \n",
      "92  @105861 if that doesn't help please dm your fu...   \n",
      "\n",
      "                                   sentence_segmented  \n",
      "0   [@applesupport causing the reply to be disrega...  \n",
      "1   [@105835 your business means a lot to us., ple...  \n",
      "2   [@76328 i really hope you all change but i'm s...  \n",
      "3   [@105836 livechat is online at the moment - ht...  \n",
      "4   [@virgintrains see attached error message., i'...  \n",
      "..                                                ...  \n",
      "88  [@105860 i wish amazon had an option of where ...  \n",
      "89  [they reschedule my shit for tomorrow https://...  \n",
      "90  [@105861 hey sara, sorry to hear of the issues...  \n",
      "91  [@tesco bit of both - finding the layout cumbe...  \n",
      "92  [@105861 if that doesn't help please dm your f...  \n",
      "\n",
      "[93 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data['text_lower'] = data['text'].str.lower()\n",
    "data['sentence_segmented'] = data['text_lower'].apply(sent_tokenize)\n",
    "\n",
    "print(data[['text', 'text_lower', 'sentence_segmented']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bf2a075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\shreya\\anaconda3\\lib\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\users\\shreya\\anaconda3\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\shreya\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\shreya\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\shreya\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shreya\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shreya\\anaconda3\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d823ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  \\\n",
      "0   @AppleSupport causing the reply to be disregar...   \n",
      "1   @105835 Your business means a lot to us. Pleas...   \n",
      "2   @76328 I really hope you all change but I'm su...   \n",
      "3   @105836 LiveChat is online at the moment - htt...   \n",
      "4   @VirginTrains see attached error message. I've...   \n",
      "..                                                ...   \n",
      "88  @105860 I wish Amazon had an option of where I...   \n",
      "89  They reschedule my shit for tomorrow https://t...   \n",
      "90  @105861 Hey Sara, sorry to hear of the issues ...   \n",
      "91  @Tesco bit of both - finding the layout cumber...   \n",
      "92  @105861 If that doesn't help please DM your fu...   \n",
      "\n",
      "                                       corrected_text  \n",
      "0   @AppleSupport causing the reply to be disregar...  \n",
      "1   @105835 Your business means a lot to us. Pleas...  \n",
      "2   @76328 I really hope you all change but I'm su...  \n",
      "3   @105836 LiveChat is online at the moment - htt...  \n",
      "4   @VirginTrains see attached error message. I've...  \n",
      "..                                                ...  \n",
      "88  @105860 I wish Amazon had an option of where I...  \n",
      "89  They schedule my shit for tomorrow http://t.co...  \n",
      "90  @105861 Key Vara, sorry to hear of the issues ...  \n",
      "91  @Esch bit of both - finding the layout cumbers...  \n",
      "92  @105861 Of that doesn't help please of your fu...  \n",
      "\n",
      "[93 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"D:/Downloads/sample.csv\")\n",
    "\n",
    "def correct_spelling(text):\n",
    "    return str(TextBlob(text).correct())\n",
    "data['corrected_text'] = data['text'].apply(correct_spelling)\n",
    "print(data[['text', 'corrected_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ec394f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Shreya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ff21fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  \\\n",
      "0   @AppleSupport causing the reply to be disregar...   \n",
      "1   @105835 Your business means a lot to us. Pleas...   \n",
      "2   @76328 I really hope you all change but I'm su...   \n",
      "3   @105836 LiveChat is online at the moment - htt...   \n",
      "4   @VirginTrains see attached error message. I've...   \n",
      "..                                                ...   \n",
      "88  @105860 I wish Amazon had an option of where I...   \n",
      "89  They reschedule my shit for tomorrow https://t...   \n",
      "90  @105861 Hey Sara, sorry to hear of the issues ...   \n",
      "91  @Tesco bit of both - finding the layout cumber...   \n",
      "92  @105861 If that doesn't help please DM your fu...   \n",
      "\n",
      "                                           text_lower  \\\n",
      "0   @applesupport causing the reply to be disregar...   \n",
      "1   @105835 your business means a lot to us. pleas...   \n",
      "2   @76328 i really hope you all change but i'm su...   \n",
      "3   @105836 livechat is online at the moment - htt...   \n",
      "4   @virgintrains see attached error message. i've...   \n",
      "..                                                ...   \n",
      "88  @105860 i wish amazon had an option of where i...   \n",
      "89  they reschedule my shit for tomorrow https://t...   \n",
      "90  @105861 hey sara, sorry to hear of the issues ...   \n",
      "91  @tesco bit of both - finding the layout cumber...   \n",
      "92  @105861 if that doesn't help please dm your fu...   \n",
      "\n",
      "                                          word_tokens  \\\n",
      "0   [@, applesupport, causing, the, reply, to, be,...   \n",
      "1   [@, 105835, your, business, means, a, lot, to,...   \n",
      "2   [@, 76328, i, really, hope, you, all, change, ...   \n",
      "3   [@, 105836, livechat, is, online, at, the, mom...   \n",
      "4   [@, virgintrains, see, attached, error, messag...   \n",
      "..                                                ...   \n",
      "88  [@, 105860, i, wish, amazon, had, an, option, ...   \n",
      "89  [they, reschedule, my, shit, for, tomorrow, ht...   \n",
      "90  [@, 105861, hey, sara, ,, sorry, to, hear, of,...   \n",
      "91  [@, tesco, bit, of, both, -, finding, the, lay...   \n",
      "92  [@, 105861, if, that, does, n't, help, please,...   \n",
      "\n",
      "                               text_without_stopwords  \n",
      "0   [@, applesupport, causing, reply, disregarded,...  \n",
      "1   [@, 105835, business, means, lot, us, ., pleas...  \n",
      "2   [@, 76328, really, hope, change, 'm, sure, wo,...  \n",
      "3   [@, 105836, livechat, online, moment, -, https...  \n",
      "4   [@, virgintrains, see, attached, error, messag...  \n",
      "..                                                ...  \n",
      "88  [@, 105860, wish, amazon, option, get, shipped...  \n",
      "89  [reschedule, shit, tomorrow, https, :, //t.co/...  \n",
      "90  [@, 105861, hey, sara, ,, sorry, hear, issues,...  \n",
      "91  [@, tesco, bit, -, finding, layout, cumbersome...  \n",
      "92  [@, 105861, n't, help, please, dm, full, name,...  \n",
      "\n",
      "[93 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "\n",
    "data['text_without_stopwords'] = data['word_tokens'].apply(remove_stopwords)\n",
    "\n",
    "\n",
    "print(data[['text', 'text_lower', 'word_tokens', 'text_without_stopwords']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bcdca85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  \\\n",
      "0   @AppleSupport causing the reply to be disregar...   \n",
      "1   @105835 Your business means a lot to us. Pleas...   \n",
      "2   @76328 I really hope you all change but I'm su...   \n",
      "3   @105836 LiveChat is online at the moment - htt...   \n",
      "4   @VirginTrains see attached error message. I've...   \n",
      "..                                                ...   \n",
      "88  @105860 I wish Amazon had an option of where I...   \n",
      "89  They reschedule my shit for tomorrow https://t...   \n",
      "90  @105861 Hey Sara, sorry to hear of the issues ...   \n",
      "91  @Tesco bit of both - finding the layout cumber...   \n",
      "92  @105861 If that doesn't help please DM your fu...   \n",
      "\n",
      "                                           text_lower  \\\n",
      "0   @applesupport causing the reply to be disregar...   \n",
      "1   @105835 your business means a lot to us. pleas...   \n",
      "2   @76328 i really hope you all change but i'm su...   \n",
      "3   @105836 livechat is online at the moment - htt...   \n",
      "4   @virgintrains see attached error message. i've...   \n",
      "..                                                ...   \n",
      "88  @105860 i wish amazon had an option of where i...   \n",
      "89  they reschedule my shit for tomorrow https://t...   \n",
      "90  @105861 hey sara, sorry to hear of the issues ...   \n",
      "91  @tesco bit of both - finding the layout cumber...   \n",
      "92  @105861 if that doesn't help please dm your fu...   \n",
      "\n",
      "                               text_without_stopwords  \\\n",
      "0   [@, applesupport, causing, reply, disregarded,...   \n",
      "1   [@, 105835, business, means, lot, us, ., pleas...   \n",
      "2   [@, 76328, really, hope, change, 'm, sure, wo,...   \n",
      "3   [@, 105836, livechat, online, moment, -, https...   \n",
      "4   [@, virgintrains, see, attached, error, messag...   \n",
      "..                                                ...   \n",
      "88  [@, 105860, wish, amazon, option, get, shipped...   \n",
      "89  [reschedule, shit, tomorrow, https, :, //t.co/...   \n",
      "90  [@, 105861, hey, sara, ,, sorry, hear, issues,...   \n",
      "91  [@, tesco, bit, -, finding, layout, cumbersome...   \n",
      "92  [@, 105861, n't, help, please, dm, full, name,...   \n",
      "\n",
      "                                       stemmed_tokens  \n",
      "0   [@, applesupport, caus, repli, disregard, tap,...  \n",
      "1   [@, 105835, busi, mean, lot, us, ., pleas, dm,...  \n",
      "2   [@, 76328, realli, hope, chang, 'm, sure, wo, ...  \n",
      "3   [@, 105836, livechat, onlin, moment, -, http, ...  \n",
      "4   [@, virgintrain, see, attach, error, messag, ....  \n",
      "..                                                ...  \n",
      "88  [@, 105860, wish, amazon, option, get, ship, u...  \n",
      "89  [reschedul, shit, tomorrow, http, :, //t.co/rs...  \n",
      "90  [@, 105861, hey, sara, ,, sorri, hear, issu, ,...  \n",
      "91  [@, tesco, bit, -, find, layout, cumbersom, re...  \n",
      "92  [@, 105861, n't, help, pleas, dm, full, name, ...  \n",
      "\n",
      "[93 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_words(tokens):\n",
    "    return [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "data['stemmed_tokens'] = data['text_without_stopwords'].apply(stem_words)\n",
    "\n",
    "print(data[['text', 'text_lower', 'text_without_stopwords', 'stemmed_tokens']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0cfa5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Shreya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Shreya\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "881e1a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  \\\n",
      "0   @AppleSupport causing the reply to be disregar...   \n",
      "1   @105835 Your business means a lot to us. Pleas...   \n",
      "2   @76328 I really hope you all change but I'm su...   \n",
      "3   @105836 LiveChat is online at the moment - htt...   \n",
      "4   @VirginTrains see attached error message. I've...   \n",
      "..                                                ...   \n",
      "88  @105860 I wish Amazon had an option of where I...   \n",
      "89  They reschedule my shit for tomorrow https://t...   \n",
      "90  @105861 Hey Sara, sorry to hear of the issues ...   \n",
      "91  @Tesco bit of both - finding the layout cumber...   \n",
      "92  @105861 If that doesn't help please DM your fu...   \n",
      "\n",
      "                                           text_lower  \\\n",
      "0   @applesupport causing the reply to be disregar...   \n",
      "1   @105835 your business means a lot to us. pleas...   \n",
      "2   @76328 i really hope you all change but i'm su...   \n",
      "3   @105836 livechat is online at the moment - htt...   \n",
      "4   @virgintrains see attached error message. i've...   \n",
      "..                                                ...   \n",
      "88  @105860 i wish amazon had an option of where i...   \n",
      "89  they reschedule my shit for tomorrow https://t...   \n",
      "90  @105861 hey sara, sorry to hear of the issues ...   \n",
      "91  @tesco bit of both - finding the layout cumber...   \n",
      "92  @105861 if that doesn't help please dm your fu...   \n",
      "\n",
      "                               text_without_stopwords  \\\n",
      "0   [@, applesupport, causing, reply, disregarded,...   \n",
      "1   [@, 105835, business, means, lot, us, ., pleas...   \n",
      "2   [@, 76328, really, hope, change, 'm, sure, wo,...   \n",
      "3   [@, 105836, livechat, online, moment, -, https...   \n",
      "4   [@, virgintrains, see, attached, error, messag...   \n",
      "..                                                ...   \n",
      "88  [@, 105860, wish, amazon, option, get, shipped...   \n",
      "89  [reschedule, shit, tomorrow, https, :, //t.co/...   \n",
      "90  [@, 105861, hey, sara, ,, sorry, hear, issues,...   \n",
      "91  [@, tesco, bit, -, finding, layout, cumbersome...   \n",
      "92  [@, 105861, n't, help, please, dm, full, name,...   \n",
      "\n",
      "                                    lemmatized_tokens  \n",
      "0   [@, applesupport, causing, reply, disregarded,...  \n",
      "1   [@, 105835, business, mean, lot, u, ., please,...  \n",
      "2   [@, 76328, really, hope, change, 'm, sure, wo,...  \n",
      "3   [@, 105836, livechat, online, moment, -, http,...  \n",
      "4   [@, virgintrains, see, attached, error, messag...  \n",
      "..                                                ...  \n",
      "88  [@, 105860, wish, amazon, option, get, shipped...  \n",
      "89  [reschedule, shit, tomorrow, http, :, //t.co/r...  \n",
      "90  [@, 105861, hey, sara, ,, sorry, hear, issue, ...  \n",
      "91  [@, tesco, bit, -, finding, layout, cumbersome...  \n",
      "92  [@, 105861, n't, help, please, dm, full, name,...  \n",
      "\n",
      "[93 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(tokens):\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "data['lemmatized_tokens'] = data['text_without_stopwords'].apply(lemmatize_words)\n",
    "print(data[['text', 'text_lower', 'text_without_stopwords', 'lemmatized_tokens']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f7cf115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  \\\n",
      "0   @AppleSupport causing the reply to be disregar...   \n",
      "1   @105835 Your business means a lot to us. Pleas...   \n",
      "2   @76328 I really hope you all change but I'm su...   \n",
      "3   @105836 LiveChat is online at the moment - htt...   \n",
      "4   @VirginTrains see attached error message. I've...   \n",
      "..                                                ...   \n",
      "88  @105860 I wish Amazon had an option of where I...   \n",
      "89  They reschedule my shit for tomorrow https://t...   \n",
      "90  @105861 Hey Sara, sorry to hear of the issues ...   \n",
      "91  @Tesco bit of both - finding the layout cumber...   \n",
      "92  @105861 If that doesn't help please DM your fu...   \n",
      "\n",
      "                                      normalized_text  \n",
      "0   applesupport causing reply disregarded tapped ...  \n",
      "1   105835 business mean lot u please dm name zip ...  \n",
      "2                    76328 really hope change sure wo  \n",
      "3   105836 livechat online moment http contact 033...  \n",
      "4   virgintrains see attached error message tried ...  \n",
      "..                                                ...  \n",
      "88  105860 wish amazon option get shipped ups stor...  \n",
      "89                      reschedule shit tomorrow http  \n",
      "90  105861 hey sara sorry hear issue ask lay speed...  \n",
      "91  tesco bit finding layout cumbersome removing i...  \n",
      "92  105861 help please dm full name address email ...  \n",
      "\n",
      "[93 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    normalized_tokens = [\n",
    "        lemmatizer.lemmatize(word) for word in tokens \n",
    "        if word.isalnum() and word not in stop_words\n",
    "    ] \n",
    "    return ' '.join(normalized_tokens)\n",
    "data['normalized_text'] = data['text'].apply(normalize_text)\n",
    "print(data[['text', 'normalized_text']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3bfe5e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Shreya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1d03611",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tokenized_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tokenized_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nltk\u001b[38;5;241m.\u001b[39mpos_tag(tokens)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Apply POS tagging to the tokenized text\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos_tags\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenized_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(pos_tagging)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenized_text\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos_tags\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tokenized_text'"
     ]
    }
   ],
   "source": [
    "def pos_tagging(tokens):\n",
    "    return nltk.pos_tag(tokens)\n",
    "\n",
    "# Apply POS tagging to the tokenized text\n",
    "data['pos_tags'] = data['tokenized_text'].apply(pos_tagging)\n",
    "\n",
    "# Display the result\n",
    "print(data[['text', 'tokenized_text', 'pos_tags']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39f366be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  \\\n",
      "0   @AppleSupport causing the reply to be disregar...   \n",
      "1   @105835 Your business means a lot to us. Pleas...   \n",
      "2   @76328 I really hope you all change but I'm su...   \n",
      "3   @105836 LiveChat is online at the moment - htt...   \n",
      "4   @VirginTrains see attached error message. I've...   \n",
      "..                                                ...   \n",
      "88  @105860 I wish Amazon had an option of where I...   \n",
      "89  They reschedule my shit for tomorrow https://t...   \n",
      "90  @105861 Hey Sara, sorry to hear of the issues ...   \n",
      "91  @Tesco bit of both - finding the layout cumber...   \n",
      "92  @105861 If that doesn't help please DM your fu...   \n",
      "\n",
      "                                          word_tokens  \\\n",
      "0   [@, applesupport, causing, the, reply, to, be,...   \n",
      "1   [@, 105835, your, business, means, a, lot, to,...   \n",
      "2   [@, 76328, i, really, hope, you, all, change, ...   \n",
      "3   [@, 105836, livechat, is, online, at, the, mom...   \n",
      "4   [@, virgintrains, see, attached, error, messag...   \n",
      "..                                                ...   \n",
      "88  [@, 105860, i, wish, amazon, had, an, option, ...   \n",
      "89  [they, reschedule, my, shit, for, tomorrow, ht...   \n",
      "90  [@, 105861, hey, sara, ,, sorry, to, hear, of,...   \n",
      "91  [@, tesco, bit, of, both, -, finding, the, lay...   \n",
      "92  [@, 105861, if, that, does, n't, help, please,...   \n",
      "\n",
      "                                             pos_tags  \n",
      "0   [(@, JJ), (applesupport, NN), (causing, VBG), ...  \n",
      "1   [(@, $), (105835, CD), (your, PRP$), (business...  \n",
      "2   [(@, $), (76328, CD), (i, NN), (really, RB), (...  \n",
      "3   [(@, RB), (105836, CD), (livechat, WP), (is, V...  \n",
      "4   [(@, NN), (virgintrains, NNS), (see, VBP), (at...  \n",
      "..                                                ...  \n",
      "88  [(@, $), (105860, CD), (i, JJ), (wish, JJ), (a...  \n",
      "89  [(they, PRP), (reschedule, VBP), (my, PRP$), (...  \n",
      "90  [(@, RB), (105861, CD), (hey, NN), (sara, NN),...  \n",
      "91  [(@, RB), (tesco, JJ), (bit, NN), (of, IN), (b...  \n",
      "92  [(@, RB), (105861, CD), (if, IN), (that, DT), ...  \n",
      "\n",
      "[93 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data['text_lower'] = data['text'].str.lower()\n",
    "data['word_tokens'] = data['text_lower'].apply(word_tokenize)\n",
    "def pos_tagging(tokens):\n",
    "    return nltk.pos_tag(tokens)\n",
    "data['pos_tags'] = data['word_tokens'].apply(pos_tagging)\n",
    "print(data[['text', 'word_tokens', 'pos_tags']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf48643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
